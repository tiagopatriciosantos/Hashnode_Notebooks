{"cells":[{"source":"# Identify fake job postings! - part 2","metadata":{"tags":[]},"cell_type":"markdown","id":"bc4e0275-1194-4e1f-9388-7b50bfaa3206"},{"source":"Problem statement:\n\n> My friend is on the job market. However, they keep wasting time applying for fraudulent job postings. They have asked me to use my data skills to filter out fake postings and save them effort.\n> They have mentioned that job postings are abundant, so they would prefer my solution to risk filtering out real posts if it decreases the number of fraudulent posts they apply to.\n> I have access to a dataset consisting of approximately 18'000 job postings, containing both real and fake jobs.\n","metadata":{},"cell_type":"markdown","id":"816208ca-f926-4714-9109-d058e8685c38"},{"source":"## Story published with Jupyter2Hashnode\n\nHave you ever struggled to convert a Jupyter Notebook into a compelling Hashnode story? If so, you're not alone. It can be a daunting task, but fortunately, there's a tool that can simplify the process: Jupyter2Hashnode.\n\nWith Jupyter2Hashnode, you can convert Jupyter Notebooks into Hashnode stories with just a single command. The tool compresses images, uploads them to the Hashnode server, updates image URLs in the markdown file, and finally, publishes the story article. It's an effortless way to transform your data analysis or code tutorials into a polished and engaging format.\n\nIf you're interested in learning more about Jupyter2Hashnode, there's a detailed guide available on Hashnode (https://tiagopatriciosantos.hashnode.dev/jupyter2hashnode-an-effortless-way-to-convert-jupyter-notebooks-to-hashnode-stories). It's a game-changing tool that can save you time and energy while helping you create high-quality content for your audience. Give it a try and see the difference for yourself!\n","metadata":{},"cell_type":"markdown","id":"caca346a-8fff-476c-a26a-714deb7313ea"},{"source":"# The part 2\n\nThis end-2-end ML (Machine Learning) project is divided into a 3 part series.\n\n- Part 1 - is all about getting to know the Dataset using Exploratory analysis, cleaning data, choosing the metrics and doing the first model prediction experiments.\n- Part 2 - is about setup of DagsHub,  DVC and MLFlow to create a version-controlled data science project, as well as tracking experiment parameters and metrics, and comparing experiments.\n- Part 3 - is all about deployment, where using MLFlow and FastApi we will deploy the model into a WebAPI and serve it with mogenius, a Virtual DevOps platform.\n\n\nCheckout the DagsHub project [here](https://dagshub.com/tiagopatriciosantos/FakeJobPostsProject).","metadata":{},"cell_type":"markdown","id":"5afd4e18-3f50-4800-98e8-709a7ca285c1"},{"source":"## Tools\n\nFor this part I will use git as and VS Code as editor.\n\nFollow the instructions to install:\n- [Git](https://github.com/git-guides/install-git)\n- [VS Code](https://code.visualstudio.com/download)\n\nI assume to have a working Python 3 installation on local system.\n","metadata":{"tags":[]},"cell_type":"markdown","id":"54f0a8db-01b1-4399-840c-49c4d97495e2"},{"source":"## What is DagsHub?\n\nhttps://dagshub.com/\n\nDagsHub is where people build data science projects. A centralized place to host, version, and manage code, data, models, experiments, and more. It allows you and your team to easily share, review, and reuse work, providing a GitHub experience for machine learning. By default DagsHub also provides a MLflow tracking server for repository.\n\n\nI will show the steps that I've used to setup the project, although feel free to follow DagsHub tutorials to get a different understand of the tool:\n1. https://dagshub.com/docs/experiment_tutorial/\n2. https://dagshub.com/docs/integration_guide/mlflow_tracking/index.html\n\n","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]},"cell_type":"markdown","id":"bf11db65-069c-4b89-a111-8c6902e12323"},{"source":"## Joining DagsHub...\n...is really easy. Just sign up. Then, after logging in, create a new repo, simply by clicking on the plus sign and create a repository in the navbar.\n\n![create_repo.png](https://dagshub.com/docs/tutorial/assets/create_repo.png)\n\n","metadata":{"tags":[]},"cell_type":"markdown","id":"d6780ebb-9caf-434d-8862-c7ac26fe1d18"},{"source":"This opens up a dialog, which should be somewhat familiar, in which you can set the repository name, description, and a few other options.\n\n![](https://i.imgur.com/JNmJldP.png)","metadata":{},"cell_type":"markdown","id":"389b7bc0-3061-4428-87f7-c57fcd2ff391"},{"source":"Let's now clone the repository into our local machine, copying the clone command on Dagshub repository.\n\n![](https://i.imgur.com/VtGOjo3.png)\n","metadata":{},"cell_type":"markdown","id":"40572924-57fb-457e-832f-8b972d2dc1d5"},{"source":"Execute this commands in the command line:\n```console\ncd path/to/folder\ngit clone https://dagshub.com/tiagopatriciosantos/FakeJobPostsProject.git\ncd FakeJobPostsProject\n```\n\nWith VS Code already installed we can now run:\n```console\ncode .\n```\n\nThat will open the VS Code editor.\n","metadata":{},"cell_type":"markdown","id":"0bde11c1-eadd-4b7e-8cd5-643c9e11eac5"},{"source":"## Creating a virtual python environment\n\nTo create and activate our virtual python environment using venv, type the following commands into your terminal (still in the project folder):\n\n\nLinux/Mac\n```console\npython3 -m venv .venv\necho .venv/ >> .gitignore\nsource .venv/bin/activate\n```\nWindows\n```powershell\npython3 -m venv .venv\necho .venv/ >> .gitignore\n.venv\\Scripts\\activate.bat\n```\n\n\nThe first command creates the virtual environment - a directory named .venv, located inside your project directory, where all the Python packages used by the project will be installed without affecting the rest of your computer.\n\nThe second command activates the virtual python environment, which ensures that any python packages we use don't contaminate our global python installation.\n\nThe rest of this tutorial should be executed in the same shell session.\nIf exit the shell session or want to create another, we need to make sure to activate the virtual environment in that shell session first.\n\n## Installing requirements\nTo install the requirements for the first part of this project, I've created a new file with the name requirements.txt and place the text inside with these direct dependencies:\n```plaintext\ndagshub==0.2.9\ndvc==2.38.1\nfsspec==2022.11.0\njoblib==1.2.0\npandas==1.5.2\nscikit-learn==1.2.0\ntyper==0.7.0\nrich==13.0.0\naiohttp==3.8.3\nmlflow==2.1.1\npython-dotenv==0.21.1\n```\n\nNow, to install type:\n```console\npip install -r requirements.txt\n```\n\n","metadata":{},"cell_type":"markdown","id":"a60cd26e-41d8-49e8-aaae-2a07f30281f9"},{"source":"## Downloading the raw data\n\nWe'll keep our data in a folder named data.\n\nIt's also important to remember to add this folder to .gitignore! We don't want to accidentally commit large data files to Git.\n\nThe following commands should take care of everything:\n\n```console\nmkdir -p data\necho /data/ >> .gitignore\n```\nLinux/Mac\n```console\nwget https://dagshub.com/tiagopatriciosantos/Datasets/raw/f3ddde257b100018bcb22a7231f899462b34c58f/data/fake_job_postings.csv -O data/fake_job_postings.csv\n```\nWindows powershell\n```powershell\nInvoke-WebRequest https://dagshub.com/tiagopatriciosantos/Datasets/raw/f3ddde257b100018bcb22a7231f899462b34c58f/data/fake_job_postings.csv -O data/fake_job_postings.csv\n```\nWindows command line\n```console\ncd data\ncurl.exe https://dagshub.com/tiagopatriciosantos/Datasets/raw/f3ddde257b100018bcb22a7231f899462b34c58f/data/fake_job_postings.csv -O fake_job_postings.csv\n```\n\n\n## Committing progress to Git\nLet's check the Git status of our project:\n\n```console\n$ git status -s\n?? .gitignore\n?? requirements.txt\n```\nNow let's commit this to Git and push to DagsHub using the command line:\n\n```console\ngit add .\ngit commit -m \"Initialized project\"\ngit push -u origin main\n```\n\nYou can now see the setup files on your DagsHub repo. So far so good.\n","metadata":{},"cell_type":"markdown","id":"8bbc700f-56d0-4c05-bd7d-41f6198c16c8"},{"source":"## Installing DVC\nInstalling DVC is as simple as To start, we need to initialize our git repo to also use DVC for data versioning:\n\n```console\ndvc init\n```","metadata":{},"cell_type":"markdown","id":"f6b9cd4f-55f4-413b-b29f-00a6a408674a"},{"source":"The following directory structure should be created:\n\n```plaintext\n.dvc\n├── .gitignore\n├── config\n├── plots\n│   ├── confusion.json\n│   ├── default.json\n│   ├── scatter.json\n│   └── smooth.json\n└── tmp\n```\n\nThis is somewhat similar to the .git folder contained in every git repo, except some of its contents will be tracked using git.\n\n- .dvc/config is similar to .git/config. By default, it's empty. More on this later on.\n- .dvc/.gitignore makes sure git ignores DVC internal files that shouldn't be tracked by Git.\n- .dvc/plots contains predefined templates for plots you can generate using dvc - more info here.\n- .dvc/tmp is used by DVC to store temporary files, this shouldn't interest the average user.\n- .dvc/cache doesn't exist yet, but it is where DVC will keep the different versions of our data files. It's very similar in principle to .git/objects.\n\n\nSome of the files generated by dvc init should be tracked by Git, so let's start by committing that:\n\n```console\ngit add .dvc\ngit commit -m \"dvc init\"\n```\n\n## Instructing DVC to track data and outputs\n\nLet's create a directory to save our outputs, outputs like the ML model we will create and save:\n```console\nmkdir -p outputs\necho /outputs/ >> .gitignore\n```\nNote that our outputs are also in .gitignore - you usually won't want to save these using Git, especially if dealing with large models like neural networks.\n\n\nNow that we have DVC installed, telling it to keep track of our data and outputs is simple with dvc add:\n\n```console\ndvc add data\ndvc add outputs\n```\n\nYou should see two new metadata files, created by DVC:\n\n```console\n$ git status -s\n M .gitignore\n?? data.dvc\n?? outputs.dvc\n\n$ cat data.dvc\nouts:\n- md5: 714b1181c5d7cb9dda66272be8be33ac.dir\n  path: data\n\n$ cat outputs.dvc\nouts:\n- md5: bc939fd1899e52dd1a5c65be0443986a.dir\n  path: outputs\n```\n\nNow, we can commit these .dvc files to Git:\n\n```console\ngit add data.dvc outputs.dvc\ngit commit -m \"Added data and outputs to DVC\"\n```\nFrom now on, this version of the data and models will be tied to this Git commit, and we'll be able to reproduce them easily later on.","metadata":{},"cell_type":"markdown","id":"4e88a4f1-651b-40d5-ab39-2d82e4af83cd"},{"source":"## Writing the code\nLet's use our existing insights and code from the data exploration level to get started writing code which:\n- Loads the data\n- Processes the data\n- Trains a classification model\n- Evaluates the trained model and reports relevant metrics.\n\nWe'll structure our project into the fowling folders and files:\n\n```plaintext\n.\n│   .dvcignore\n│   .env    --> File to store local environment variables\n│   .gitignore\n│   data.dvc\n│   LICENSE\n│   main.py    --> File that is the starting point of our cli application\n│   outputs.dvc\n│   README.md\n│   requirements.txt    --> File that have all the necessary dependencies to make our project run\n├───.dvc\n│   │   .gitignore\n│   │   config\n│   ├───cache\n│   └───tmp\n├───custom_code    --> folder to store the custom code like class's\n│       transformer.py    -> StringConcatTransformer trasnformer that will concat columns\n│       __init__.py\n├───data    --> folder to store the data\n│       fake_job_postings.csv\n├───outputs    --> folder to store outputs like the ML model\n├───src    --> folder to store code that executes preprocess, training, model evaluation, ...\n│   │   constants.py\n│   │   data_preprocess.py\n│   │   model.py\n```\n\n\nYou can find the full code at https://dagshub.com/tiagopatriciosantos/FakeJobPostsProject\n\nLet's dig into some code explanation:\n","metadata":{},"cell_type":"markdown","id":"a513aa5b-9f46-48ee-81df-1675e1620432"},{"source":"### `.env`\n\nThis file stores the necessary environment variables and will be used when calling `load_dotenv()`\n\n```plaintext\nMLFLOW_TRACKING_USERNAME=tiagopatriciosantos\nMLFLOW_TRACKING_PASSWORD=<secret>\n```\n\n\n🚩🚨 Don't forget to include this file in the `.gitignore` file, you don't want to push to your public repository your secrets.\n```console\necho .env >> .gitignore\n```\n\n\nWe can get the necessary MLFlow values from Dagshub repository:\n\n![](https://i.imgur.com/yaJNfXf.png)\n","metadata":{},"cell_type":"markdown","id":"717f871c-1aaa-4e0d-8096-abbd68fa12d2"},{"source":"\n### `main.py`\n\n- We call `load_dotenv` to load the necessary environment variables\n- Using `Repo` we store the current git branch name\n- We then set `MLFlow` to track our mlflow dagshub uri and the experiment name as our current git branch name, we set also that mlflow will autolog but not the model, we will \"manually\" save the model with some custom information [Dagshub integration guide](https://dagshub.com/docs/integration_guide/mlflow_tracking/index.html#:~:text=logging%20functions.%20.-,2.%20Set%20DagsHub%20as%20the%20remote%20URI,-%C2%B6) | [MLFlow docs](https://mlflow.org/docs/latest/python_api/mlflow.html?highlight=autolog#mlflow.autolog)\n- Used `Typer` library for building the CLI application [Typer docs](https://typer.tiangolo.com/)\n- We have created 4 different commands that can be called in the command line, check the docstrings in the code to found out more\n\n\n```python\nimport typer\nimport mlflow\nfrom git import Repo\nfrom src import data_preprocess\nfrom src import model\nfrom rich import print\n\n## loads environment variables from .env file\nfrom dotenv import load_dotenv\nload_dotenv() \n\n## gets the current git local branch name\nlocal_repo = Repo(path=\".\")\nlocal_branch = local_repo.active_branch.name\n\n\nmlflow.set_tracking_uri(\"https://dagshub.com/tiagopatriciosantos/FakeJobPostsProject.mlflow\")\nmlflow.set_experiment(local_branch)\nmlflow.sklearn.autolog(log_models=False)\n\napp = typer.Typer()\n\n@app.command()\ndef clean():\n    \"\"\"\n    This function cleans the raw data from the CSV file.\n    The cleaned data is saved to a new CSV file.\n    \"\"\"\n    data_preprocess.clean()\n \n\n\n@app.command()\ndef split():\n    \"\"\"\n    Split the data into train and test sets.\n    This function will create 2 files:\n        TRAIN_DF_PATH\n        TEST_DF_PATH\n    \"\"\"\n    data_preprocess.split()\n\n@app.command()\ndef train():\n    \"\"\"\n    This function trains a model on the data in the TRAIN_DF_PATH and TEST_DF_PATH files.\n    It saves the trained model to the outputs/model.joblib file.\n    It logs the model's hyperparameters and metrics to DAGsHub.\n    \"\"\"\n    model.train()\n\n@app.command()\ndef runall():\n    \"\"\"\n    Run all the steps of the pipeline.\n    \"\"\"\n    data_preprocess.clean()\n    data_preprocess.split()\n    model.train()\n\n\nif __name__ == '__main__':\n    app()\n\n```\n\n","metadata":{},"cell_type":"markdown","id":"a8b90a64-3507-4daa-90fb-ff7b9bfe16b6"},{"source":"### `src/data_preprocess.py`\n\nThis files contains the code to:\n- Clean the the raw data from the CSV file.It removes non-ascii characters, strips the text and inserts one whitespace between lower capital letter and capitalized letter. The cleaned data is saved to a new CSV file.\n- Feature engineering\n- Splits the data into train and test set and writes them to files\n- For our first experiment we will only select the columns `title`, `description` ,`has_company_logo`\n    ","metadata":{},"cell_type":"markdown","id":"1524468f-006f-492d-83f4-9a761b769853"},{"source":"### `src/model.py`\n\nThis file contains the code necessary to build, train and evaluate the model.\n\n`_build_model`:\n- The model is a pipeline were we will have some initial transformers that will work the features to use in our model to train and evaluate\n- `col_selector` will force to use only the defined columns that we want in this experiment, we need to call `set_output` to \"pandas\" to retain a Dataframe structure with columns names\n- `StringConcatTransformer` will join the columns  [\"title\",\"description\"] \n- the column \"has_company_logo\" does not need any transformation as it always have values between 0 and 1\n- The final estimator in our first experiment will be the Logistic regression\n\nThe `eval_model` function evaluates a trained model on data set using the average precision, precision, recall, and f1-score metrics.\n\n`train`:\n- the `train` function will load the csv, call our `_build_model` function, train, evaluate and save the model\n- using the `dagshub_logger` we save the metrics and the `model.joblib` into our outputs folder, we then can upload into our repository this outputs\n- using mlflow.start_run() as we set the `autolog()` autologging is performed when you call estimator.fit(), estimator.fit_predict() or estimator.fit_transform() and will save the different default metrics\n- `mlflow.pyfunc.log_model` Log a wrapped custom model as an MLflow artifact for the current run. Because we have a custom transformer in our pipeline and the model wrapper we need to set `code_path` to this custom code so is available when loading this model. Will store all the artifacts under the path named `master` and will register the model as `main` a registered_model_name.\n[MLFlow docs](https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.log_model)\n\n```python\nimport dagshub\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom rich import print\nfrom .constants import *\nimport joblib\nimport mlflow\nfrom mlflow.models import infer_signature\nfrom custom_code import StringConcatTransformer, ModelWrapper\n\ndef _build_model():\n\n    cols = [\"title\",\"description\", \"has_company_logo\"]\n    # transformer to filter columns\n    col_selector = ColumnTransformer([ (\"cols\", \"passthrough\", cols)  ],remainder=\"drop\",verbose_feature_names_out=False )\n    col_selector.set_output(transform=\"pandas\")\n\n    # transformer to join text columns and apply TfidfVectorizer\n    text_preprocess = ColumnTransformer(\n        [(\n            'processing', \n            Pipeline([\n                        (\"concat\", StringConcatTransformer() ), \n                        (\"vect\",TfidfVectorizer(max_features=25000, ngram_range=(1,2)) )\n                    ]), \n            ['title', 'description']\n        )], \n        remainder=\"passthrough\")\n\n    # create the final pipeline with preprocessing steps and \n    # the final classifier step\n    pipeline = Pipeline([\n        (\"select\", col_selector),\n        ('text', text_preprocess),\n        ('clf', LogisticRegression(random_state=RANDOM_SEED, max_iter=500))\n    ])\n\n    return pipeline\n\ndef eval_model(estimator, X, y, threshold=0.5):\n    \"\"\"\n    Evaluate a model using the metrics:\n        - average_precision\n        - precision\n        - recall\n        - f1\n    \n    Parameters\n    ----------\n    estimator : sklearn estimator\n        The estimator to evaluate.\n    X : array-like, shape (n_samples, n_features)\n        The input samples.\n    y : array-like, shape (n_samples,)\n        The target values.\n    \n    Returns\n    -------\n    dict\n        A dictionary containing the metrics.\n    \"\"\"\n    \n    y_proba = estimator.predict_proba(X)[:,1]\n\n    y_pred = y_proba > threshold\n    \n\n    return {\n        'average_precision': metrics.average_precision_score(y, y_proba),\n        'precision': metrics.precision_score(y, y_pred),\n        'recall': metrics.recall_score(y, y_pred),\n        'f1': metrics.f1_score(y, y_pred)\n    }\n\ndef train():\n    \"\"\"\n    This function trains a model on the data in the TRAIN_DF_PATH and TEST_DF_PATH files.\n    It saves the trained model to the outputs/model.joblib file.\n    It logs the model's hyperparameters and metrics to DAGsHub.\n    \"\"\"\n    print('Loading data from files', TRAIN_DF_PATH, TEST_DF_PATH,\"...\")\n    train_df = pd.read_csv(TRAIN_DF_PATH)\n    test_df = pd.read_csv(TEST_DF_PATH)\n\n    X_train = train_df.drop(columns=[CLASS_LABEL])\n    y_train = train_df[CLASS_LABEL]\n    X_test = test_df.drop(columns=[CLASS_LABEL])\n    y_test = test_df[CLASS_LABEL]\n\n    with dagshub.dagshub_logger(metrics_path=\"./outputs/metrics.csv\", hparams_path=\"./outputs/params.yml\") as logger, mlflow.start_run() as run:\n    \n        \n        print('Building the model...')\n        model = _build_model()\n\n        print('Training the model...')\n        \n        model.fit(X_train, y_train)\n        \n        print('Saving trained model...')\n        joblib.dump(model, 'outputs/model.joblib')\n\n        print(model.get_params())\n        logger.log_hyperparams({'model': model.get_params()})\n\n        model_clf_name = model.get_params()[\"clf\"].__class__.__name__\n\n        mlflow.set_tag('estimator_name', model_clf_name )\n\n        # based on our analysis we will define this threshold\n        threshold=0.0485\n        print('Evaluating model...')\n        train_metrics = eval_model(model, X_train, y_train, threshold)\n\n        print('Threshold:', threshold)\n        mlflow.set_tag('estimator_threshold', threshold )\n        threshold_to_log= {\"threshold\":threshold}\n        logger.log_metrics(threshold_to_log)\n        mlflow.log_metrics(threshold_to_log)\n\n\n        print('Train metrics:')\n        print(train_metrics)\n        metrics_to_log = {f'train__{k}': v for k,v in train_metrics.items()}\n        logger.log_metrics(metrics_to_log)\n        mlflow.log_metrics(metrics_to_log)\n\n        test_metrics = eval_model(model, X_test, y_test, threshold)\n        print('Test metrics:')\n        print(test_metrics)\n        metrics_to_log = {f'test__{k}': v for k,v in test_metrics.items()}\n        logger.log_metrics(metrics_to_log)\n        \n        mlflow.log_metrics(metrics_to_log)\n\n        y_pred =  model.predict_proba(X_test)[:,1]>0.5\n\n        signature = infer_signature(X_test, y_pred)\n\n        mlflow.pyfunc.log_model(\"master\", \n                                python_model=ModelWrapper(model, threshold=threshold),\n                                signature=signature,\n                                code_path=[\"custom_code\"],\n                                registered_model_name=\"main\",\n                                await_registration_for=10,\n                                input_example = X_test.sample(5, random_state=RANDOM_SEED),\n                                metadata=threshold_to_log\n                                )\n```","metadata":{},"cell_type":"markdown","id":"d30f6cf1-bc47-4fc8-b78f-59a55b258153"},{"source":"### `custom_code/transformer.py`\n\nThis file contains the class `StringConcatTransformer`, this class concatenate multiple string fields into a single field, inherits from TransformerMixin, BaseEstimator and ClassNamePrefixFeaturesOutMixin so we can use it in the Pipeline.\n\n```python\nfrom sklearn.base import TransformerMixin, BaseEstimator, ClassNamePrefixFeaturesOutMixin\nimport numpy as np\n\nclass StringConcatTransformer(TransformerMixin, BaseEstimator, ClassNamePrefixFeaturesOutMixin):\n    \"\"\"Concatenate multiple string fields into a single field.\n    \"\"\"\n    \n    def __init__(self, missing_indicator=''):\n        \"\"\"\n        NAN value will be replaced by missing_indicator\n        \"\"\"\n        self.missing_indicator = missing_indicator\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return np.array(X.fillna(self.missing_indicator).agg(' '.join, axis=1))\n\n    def get_feature_names_out(self,input_features=None):\n        return np.array([\"Text\"])\n\n```\n\n","metadata":{},"cell_type":"markdown","id":"8916d5d0-12d6-4012-b516-187d770b8e84"},{"source":"`custom_code/model.py`\n\nThis file contains the class `ModelWrapper`, creates a wrapper for our model.\n\n```python\nfrom mlflow.pyfunc import PythonModel, PythonModelContext\nimport numpy as np\n\nclass ModelWrapper(PythonModel):\n    def __init__(self, model, threshold=0.5):\n        self._model = model\n        self._threshold = threshold\n    \n    #custom predict function using specific treshold\n    def predict(self, context: PythonModelContext, data):\n        return np.array(self._model.predict_proba(data)[:,1]>=self._threshold)\n\n```\n","metadata":{},"cell_type":"markdown","id":"d74a8dc4-f777-4813-98d1-a616725c5885"},{"source":"## Executing the first experiment\n\nRunning the command we can see the commands we can execute:\n\n`python main.py --help`\n\n![](https://i.imgur.com/FX0LsXt.png)\n\n\nWe will run now the commands, we start with the clean:\n\n`python main.py clean`\n\n```console\nLoading data from file data/fake_job_postings.csv ...\nCleaning data...\nSaving data...\nClean completed, saved to file data/clean_fake_job_postings.csv.zip\n```\n\n\nLet's split the data into train and test:\n\n`python main.py split`\n\n```console\nLoading data from file data/clean_fake_job_postings.csv.zip ...\nSaving split data...\nSplit completed, created 2 files data/train.csv.zip data/test.csv.zip\n```\n\nLet's now build the model, train and evaluate:\n\n`python main.py train`\n\n```console\n...\nModel name: main, version 1\nCreated version '1' of model 'main'.\n```\n\n\n\n\n","metadata":{},"cell_type":"markdown","id":"b2699e20-9bd9-4b01-a829-e6df71cfeebd"},{"source":"## Committing progress to Git, again\n\nSo, until now we have made a lot of progress, with last step we have executed the experimentation, that generated files and uploaded info to the remote MLflow server provided by  Dagshub.\n\nLet's check the DVC status of our project:\n```console\n$ dvc status\ndata.dvc:\n        changed outs:\n                modified:           data\noutputs.dvc:\n        changed outs:\n                modified:           outputs\n```\n\nWe can see that we have new data and outputs, so we need to commit:\nTo record the md5 of the new model, and save it to .dvc/cache, as well as the data files created when cleanning and splitting the raw Dataset, we now can run:\n```console\ndvc commit -f\n```\nThis updates the outputs.dvc and data.dvc files with the hash of the new files, as well as store in .dvc/cache, let's see them:\n```console\n$ cat data.dvc\nouts:\n- md5: ea9d5d288c7904bbc412a2064dfa22f9.dir\n  size: 83661055\n  nfiles: 4\n  path: data\n  \n$ cat outputs.dvc\nouts:\n- md5: 7b0ef7da6f9aa6ce1069530121b7bf7d.dir\n  size: 32650684\n  nfiles: 3\n  path: output\n```\n\nLet's check the Git status of our project:\n\n```console\n$ git status -s\n M .gitignore\n M requirements.txt\n?? custom_code/\n?? data.dvc\n?? main.py\n?? outputs.dvc\n?? src/\n```\n\nNow let's commit this to Git and push to DagsHub using the command line:\n\n```console\ngit add .\ngit commit -m \"First LogisticRegression experiment\"\n```\n","metadata":{},"cell_type":"markdown","id":"21ccd6cf-335d-42ea-b527-61193240ee7c"},{"source":"## Pushing code, data, and models to DagsHub\n\nIt's great to have saved versions of our data and models in our local workspace, but what if we have team members? Or if we want to continue work on some other machine?\n\nDagsHub has you covered - not only can you push your Git code history to DagsHub, but you can also push (and later pull) all DVC managed files!\n\nLets create a script file to ask for the repo, user name and password to store in dvc config files:\nLinux/Mac script `set_dagshub_repo.sh`\n```plaintext\necho -n \"Username: \"\nread DAGSHUB_USER\necho -n \"Repo name: \"\nread DAGSHUB_REPO\necho -n \"Password: \"\nread -s DAGSHUB_PASS\ndvc remote add origin \"https://dagshub.com/$DAGSHUB_USER/$DAGSHUB_REPO.dvc\"  -f\ndvc remote default origin --local\ndvc remote modify origin --local user \"$DAGSHUB_USER\"\ndvc remote modify origin --local auth basic\ndvc remote modify origin --local password \"$DAGSHUB_PASS\"\nunset DAGSHUB_PASS\n```\nWindows bat file `set_dagshub_repo.bat`\n```powershell\nset /p DAGSHUB_USER=\"Username: \"\nset /p DAGSHUB_REPO=\"Repo name: \"\nset /p DAGSHUB_PASS=\"Password: \"\ndvc remote add origin https://DagsHub.com/%DAGSHUB_USER%/%DAGSHUB_REPO%.dvc\"  -f\ndvc remote default origin\ndvc remote modify origin --local user %DAGSHUB_USER%\ndvc remote modify origin --local auth basic\ndvc remote modify origin --local password %DAGSHUB_PASS%\nset DAGSHUB_PASS=\n```\n\nWe can now execute the script and fill in the values:\nLinux/Mac\n```console\n$ sh set_dagshub_repo.sh\n\n```\nWindows\n```powershell\n> .\\set_dagshub_repo.bat\n```\n\n\nYou can see that some DVC stores some configurations in .dvc/config, which should be committed to Git:\n```console\n$ git diff\ndiff --git a/.dvc/config b/.dvc/config\nindex e69de29..2d69bfe 100644\n--- a/.dvc/config\n+++ b/.dvc/config\n@@ -0,0 +1,4 @@\n+[core]\n+    remote = origin\n+['remote \"origin\"']\n+    url = https://DagsHub.com/tiagopatriciosantos/FakeJobPostsProject.dvc\n```\n\n🚩🚨 Why use --local in the DVC remote commands?\n> Only configurations that are shared across collaborators should be stored in .dvc/config. The other configuration file is .dvc/config.local - it functions identically to .dvc/config, except it's ignored by Git. That's the correct way to store things like usernames and passwords. We used the --local flag to indicate to DVC that these configuration keys should only be stored locally.\n> Make sure not to accidentally commit secret information to .dvc/config!\n\n\nSo, let's commit these configuration changes to git:\n\n```console\ngit add .dvc/config\ngit commit -m \"Configured the DVC remote\"\n```\n\nAnd push to our repo:\n```console\ngit push -u origin main\ndvc push --all-commits\n```\nNow, any future collaborator can git clone and then dvc pull the data and models from any version.\n","metadata":{},"cell_type":"markdown","id":"8cdb3d06-897d-4a53-b7ee-61c7b298b754"},{"source":"## Executing a new experiment\n\nNow, to run a different experiment, for example using a `RandomForestClassifier`, the best approach is to create a new branch.\n\nNow, we can let our imaginations run free with different configurations for experiments.\n\nHere are a few examples:\n\n- We can change the type of model:\n    - Random Forest model – model.py with RandomForestClassifier\n    - Neural Network model – model.py with MLPClassifier\n- Adding features and onehotencoding\n- We can play around with parameters:\n    - We can try out different values for random forest's max_depth parameter – main.py with different max depth\n- Etc.\n\nAfter each such modification, we'll want to save our code and models. We can do that by running a set of commands like this:\n\n```console\npython3 main.py train\ndvc commit -f outputs.dvc\ngit checkout -b \"Experiment branch name\"  # It is recommended separating distinct experiments to separate branches. Read more in the note below.\ngit add .\ngit commit -m \"Description of the experiment\"\ngit checkout main\n```\n\n🗺 Branching strategy for experiments\n\n> Its often hard to decide what structure to use for your project, and there are no right answers – it depends on your needs and preferences.\n> Dagshub recommendation is to separate distinct experiments (for example, different types of models) into separate branches, while smaller changes between runs (for example, changing model parameters) are consecutive commits on the same branch.\n\n## Pushing our committed experiments to DagsHub\nTo really start getting the benefits of DagsHub, we should now push our Git commit, which captures an experiment and its results, to DagsHub. That will allow us to visualize results.\n\n```console\n# You may be asked for your DagsHub username and password when running this command\ngit push --all\ndvc push --all-commits\n```","metadata":{},"cell_type":"markdown","id":"9f41cc26-0f91-4f8d-a043-c0695eba2309"},{"source":"## Visualizing experiments on DagsHub\n\nTo see our experiments visualized, we can navigate to the \"Experiments\" tab in our DagsHub repo:\n![](https://i.imgur.com/SuYsjm2.png)\n\n\nThis table has a row for each detected experiment in your Git history, showing its information and columns for hyperparameters and metrics. \nEach of these rows corresponds to a experiment train call.\n\nYou can interact with this table to:\n- Filter experiments by hyperparameters: Filter experiments by model class\n- Filter & sort experiments by numeric metric values - i.e. easily find your best experiments: Filter experiments by minimum F1 test score\n- Choose the columns to display in the table - by default, we limit the number of columns to a reasonable number: Choose displayed columns\n- Label experiments for easy filtering.\n- Experiments labeled hidden are automatically hidden by default, but you can show them anyway by removing the default filter. Apply freestyle labels to experiments\n- Select experiments for comparison.\n- For example, we can check the top 3 best experiments: Select 3 experiments, then click on the Compare button to see all 3 of them side by side\n\n","metadata":{},"cell_type":"markdown","id":"97cbb263-5cb1-4507-aead-717943325662"},{"source":"## MLflow UI\n\nThe DagsHub MLflow tracking server provides access to the MLflow server user interface (MLflow UI). To view the MLflow UI, visit the tracking server URI (https:\\/\\/dagshub.com/\\<username\\>/\\<repo\\>.mlflow) in a browser. If you haven't interacted with the main DagsHub interface in a while, you may have to enter your DagsHub username and password/access token in to the authentication popup shown by your browser.\n\nYou should have full access to all views and actions provided by the MLflow UI. This includes viewing run details, comparing runs (within the same experiment only, to compare runs across experiments, visit the DagsHub experiment tracking interface), creating and managing experiments, and viewing and updating the model registry.\n    \nWe can enter into the MLFlow UI clicking on the button \"Go to mlflow UI\" under the Remote->Experiments \n![](https://i.imgur.com/us1cqcZ.png)    \n","metadata":{},"cell_type":"markdown","id":"eb5b7ff7-eebb-4ba9-8f86-67043653242f"},{"source":"## Part 2 conclusion\n\nIn this part of the project, the setup of DagsHub, DVC, and MLFlow was demonstrated to create a version-controlled data science project, as well as tracking experiment parameters and metrics and comparing experiments. The steps for creating a virtual Python environment, installing requirements, and downloading raw data were also discussed. Finally, the code to load, process, train, and evaluate a classification model was shown, with environment variables stored in the .env file and tracked using MLFlow. This part of the project demonstrates the importance of using tools like DagsHub, DVC, and MLFlow to simplify data science workflows and ensure reproducibility.","metadata":{},"cell_type":"markdown","id":"b0dbf907-9809-4f91-bd27-fc4aa28aa13d"},{"source":"# Next...","metadata":{},"cell_type":"markdown","id":"c4a3bc7f-0eef-4c47-8b9d-3290d0f2b617"},{"source":"In the next part of this series we will use the MLFlow UI to serve the choosen model, create a WebAPI using FastAPI and deploy using Mogenius.","metadata":{},"cell_type":"markdown","id":"2de15e44-0050-4186-befc-22e045222af1"}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"toc-autonumbering":true,"toc-showmarkdowntxt":false,"toc-showcode":false},"nbformat":4,"nbformat_minor":5}